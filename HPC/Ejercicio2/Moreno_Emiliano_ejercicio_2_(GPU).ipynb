{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Moreno_Emiliano_ejercicio_2_(GPU).ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw-Vno_15t-E"
      },
      "source": [
        "# 1 Introducción\n",
        "El siguiente cuaderno realiza la transpuesta de una matriz, utilizando GPGPU. El kernel ejecuta en hilos sobre dos dimensión (X e Y).\n",
        "\n",
        "Para la resolución se aplicaron conceptos de Lenguaje Python, CUDA y el manejo de operaciones aritméticas sobre matrices.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cRnhv_7N4Pa"
      },
      "source": [
        "---\n",
        "# 2 Armado del ambiente\n",
        "Instala en el cuaderno el módulo CUDA de Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z74FNbCszDmw"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzQaWRTtc1Zj"
      },
      "source": [
        "---\n",
        "# 3 Desarrollo\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9c7mZSnu0M3m"
      },
      "source": [
        "# --------------------------------------------\n",
        "#@title 3.1 Parámetros de ejecución { vertical-output: true }\n",
        "\n",
        "cantidad_N =   2#@param {type: \"number\"}\n",
        "\n",
        "# --------------------------------------------\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "tiempo_total = datetime.now()\n",
        "\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "# --------------------------------------------\n",
        "# Definición de función que transforma el tiempo en  milisegundos \n",
        "tiempo_en_ms = lambda dt:(dt.days * 24 * 60 * 60 + dt.seconds) * 1000 + dt.microseconds / 1000.0\n",
        "\n",
        "# CPU - Defino la memoria de la matriz.\n",
        "M_cpu = numpy.random.randn( cantidad_N, cantidad_N)\n",
        "M_cpu = M_cpu.astype( numpy.float32() )\n",
        "T_cpu = numpy.random.randn( cantidad_N, cantidad_N)\n",
        "T_cpu = T_cpu.astype( numpy.float32() )\n",
        "\n",
        "tiempo_ini_cpu = datetime.now()\n",
        "\n",
        "# CPU - reservo la memoria GPU.\n",
        "M_gpu = cuda.mem_alloc( M_cpu.nbytes )\n",
        "T_gpu = cuda.mem_alloc( T_cpu.nbytes )\n",
        "\n",
        "# GPU - Copio la memoria al GPU.\n",
        "cuda.memcpy_htod( M_gpu, M_cpu )\n",
        "cuda.memcpy_htod( T_gpu, T_cpu )\n",
        "\n",
        "# CPU - Defino la función kernel que ejecutará en GPU.\n",
        "module = SourceModule(\"\"\"\n",
        "__global__ void MatrizTranspuesta( int rows, int cols, float *mat_in, float *mat_out )\n",
        "{\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x; \n",
        "    int idy = threadIdx.y + blockIdx.y * blockDim.y;\n",
        "    if(idx < cols && idy < rows){\n",
        "        int pos = idy * cols + idx;\n",
        "        int trans_pos = idx * rows + idy;\n",
        "\n",
        "        mat_out[trans_pos] = mat_in[pos];\n",
        "    } \n",
        "}\n",
        "\"\"\") \n",
        "\n",
        "# CPU - Genero la función kernel.\n",
        "kernel = module.get_function(\"MatrizTranspuesta\")\n",
        "\n",
        "tiempo_gpu = datetime.now()\n",
        "\n",
        "# GPU - Ejecuta el kernel.\n",
        "dim_hilo_x = 16\n",
        "dim_bloque_x = numpy.int( (cantidad_N+dim_hilo_x-1) / dim_hilo_x )\n",
        "\n",
        "dim_hilo_y = 16\n",
        "dim_bloque_y = numpy.int( (cantidad_N+dim_hilo_y-1) / dim_hilo_y )\n",
        "\n",
        "kernel( numpy.int32(cantidad_N), numpy.int32(cantidad_N), M_gpu, T_gpu, block=( dim_hilo_x, dim_hilo_y, 1 ), grid=(dim_bloque_x, dim_bloque_y,1) )\n",
        "tiempo_gpu = datetime.now() - tiempo_gpu\n",
        "\n",
        "# GPU - Copio el resultado desde la memoria GPU.\n",
        "cuda.memcpy_dtoh( T_cpu, T_gpu )\n",
        "\n",
        "#\"\"\"\n",
        "# CPU - Informo el resutlado.\n",
        "print( \"------------------------------------\")\n",
        "print( \"Matriz M: \" )\n",
        "print( M_cpu )\n",
        "print( \"------------------------------------\")\n",
        "print( \"Transpuesta T: \" )\n",
        "print( T_cpu )\n",
        "#\"\"\"\n",
        "\n",
        "tiempo_total = datetime.now() - tiempo_total\n",
        "\n",
        "print( \"Cantidad de elementos N: \", cantidad_N )\n",
        "print( \"Cantidad de elementos M: \", cantidad_N )\n",
        "print( \"Thread x: \", dim_hilo_x, \", Bloque x:\", dim_bloque_x )\n",
        "print( \"Thread y: \", dim_hilo_y, \", Bloque y:\", dim_bloque_y )\n",
        "print(\"Tiempo CPU: \", tiempo_en_ms( tiempo_total ), \"[ms]\" )\n",
        "print(\"Tiempo GPU: \", tiempo_en_ms( tiempo_gpu   ), \"[ms]\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EALIlyyG6iqP"
      },
      "source": [
        "---\n",
        "# 4 Tabla de pasos de ejecución del programa\n",
        "\n",
        "\n",
        " Procesador | Funciòn | Detalle\n",
        "------------|---------|----------\n",
        "CPU      |  @param                | Lectura del tamaño de vectores desde Colab.\n",
        "CPU      |  import                | Importa los módulos para funcionar.\n",
        "CPU      |  datetime.now()        | Toma el tiempo actual.\n",
        "CPU      |  numpy.random.randn( Cantidad_N ) | Inicializa las matrices M y T\n",
        "**GPU**  |  cuda.mem_alloc()      | Reserva la memoria en GPU.\n",
        "**GPU**  |  cuda.memcpy_htod()    | Copia las memorias desde el CPU al GPU.\n",
        "CPU      |  SourceModule()        | Define el código del kernel \n",
        "CPU      |  module.get_function() | Genera la función del kernel GPU\n",
        "CPU      |  dim_tx/dim_bx         | Calcula las dimensiones.\n",
        "**GPU**  |  kernel()              | Ejecuta el kernel en GPU\n",
        "CPU      |  cuda.memcpy_dtoh( )   | Copia el resultado desde GPU memoria R a CPU memoria R.\n",
        "CPU      |  print()               | Informo los resultados.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzgZkrQD-UTy"
      },
      "source": [
        "---\n",
        "# 5 Conclusiones\n",
        "\n",
        "A medida que aumenta la cantidad de elementos de la matriz aumenta el tiempo de procesamiento. A pesar de que en GPU tenemos más funciones y pasos para ejecutar (ej. reservar la memoria en area de GPU, copia de datos, definir y compilar Kernel, ejecución de Kernel) podemos notar que al realizar la transpuesta de la matriz de NxN elementos hacerlo con GPU reduce mucho el tiempo total comparado con el tiempo total de la misma operación solo con CPU. Esto ultimo se debe a que en GPU la ejecución se realiza mediante hilos concurrentes.\n",
        "\n",
        "**Sugerencias de mejora:** \n",
        "\n",
        "1) Se podria realizar una mejora para que el algoritmo funcione para matrices no cuadradas. Ejemplo \n",
        " N = 4 (filas)\n",
        " M = 2 (columnas)\n",
        "\n",
        "2) Se podria realizar una mejora para que el algoritmo permita ejecutar operaciones y realizar comprobaciones de las propiedades con más de una matriz. Por ejemplo: la suma traspuesta de matrices es igual a la suma de las matrices traspuestas: (X+Z) EXP T = X EXP T + Z EXP T.\n",
        "\n",
        "De esta manera el algoritmo podria servir aún más para fines educativos. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hn6HOCYEjyY"
      },
      "source": [
        "---\n",
        "# 6 Bibliografia\n",
        "\n",
        "Introducción a Python: [Página Colab](https://github.com/wvaliente/SOA_HPC/blob/main/Documentos/Python_Basico.ipynb) \n",
        "\n",
        "Documentación PyCUDA: [WEB](https://documen.tician.de/pycuda/index.html)\n",
        "\n",
        "Paginas de Referencia: [WEB]\n",
        "\n",
        "https://stackoverrun.com/es/q/3720173\n",
        "\n",
        "https://fisica.cab.cnea.gov.ar/gpgpu/images/clases/clase7_multiplicacion%20de%20matrices.pdf\n",
        "\n",
        "https://developer.nvidia.com/blog/efficient-matrix-transpose-cuda-cc/\n",
        "\n",
        "\n"
      ]
    }
  ]
}